{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "import pycurl\n",
    "import json\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import http.client as http\n",
    "plt.rcParams['figure.figsize'] = [50, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting price data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First of all we must get the indicator so we can acquire the info of that indicator from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_recollection(object):\n",
    "    \"\"\"\n",
    "    With this class we are resuming all the steps for getting the data into some functions. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        None\n",
    "        \n",
    "    def get_list_indicators(self):\n",
    "        \"\"\"\n",
    "        A function to get the list of all the indicators that we can find in the ESIOS API\n",
    "        \"\"\"\n",
    "        token = '3eae9719f5c8a0dff1c71bb3a6e709bbc37bfce5f6df3662789a1c6fee2ebd67'\n",
    "        #First, we set the url:\n",
    "        url_esios1='https://api.esios.ree.es/indicators'\n",
    "        #After that, we manage to request the dictionary with the indicators from the webpage:\n",
    "        request = urllib.request.Request(url_esios1)\n",
    "        head=[\"Authorization: Token token=\\\"\"+token+\"\\\"\"]\n",
    "        request.add_header(\"Authorization\",\"Token token=\\\"\"+token+\"\\\"\")\n",
    "        response = urllib.request.urlopen(request)\n",
    "        responseStr = str(response.read().decode('utf-8'))\n",
    "\n",
    "        # We fetch json from the response\n",
    "        js = json.loads(responseStr)\n",
    "\n",
    "        dicc=js['indicators']\n",
    "\n",
    "        #We put the results into a list so we can look through it:\n",
    "        busqueda=[]\n",
    "        for diccionario in dicc:\n",
    "            busqueda.append(diccionario)\n",
    "        # Finally, we return de results\n",
    "        return busqueda\n",
    "\n",
    "    def get_indicator(self,indicator,date_today=date.today().strftime(\"%Y-%m-%d\")):\n",
    "        \"\"\"\n",
    "        With this function we will connect to the server of ESIOS and we will get the info of the indicator that we want until the\n",
    "        date that we indicate. As default, it will be set until today. The parameters are:\n",
    "            - indicator: number of the indicator according to the dictionary that we have\n",
    "            - date: limit day for the info. format \"Year-month-day\"\n",
    "        \"\"\"\n",
    "        token = '3eae9719f5c8a0dff1c71bb3a6e709bbc37bfce5f6df3662789a1c6fee2ebd67'\n",
    "        # We change the http from 1.1 to 1.0 beacuse it sometimes gives problems when requesting the data \n",
    "        http.HTTPConnection._http_vsn = 10\n",
    "        http.HTTPConnection._http_vsn_str = 'HTTP/1.0'\n",
    "        # Set URL value\n",
    "        url='https://api.esios.ree.es/indicators/'+str(indicator)+'?start_date=2014-04-01T00%3A00%3A00Z&end_date='+date_today+'T23%3A50%3A00Z&groupby=hour'\n",
    "        # Get the request\n",
    "        request = urllib.request.Request(url)\n",
    "        request.add_header(\"Authorization\",\"Token token=\\\"\"+token+\"\\\"\")\n",
    "        response = urllib.request.urlopen(request)\n",
    "        responseStr = str(response.read().decode('utf-8'))\n",
    "        # Fetch json from the response\n",
    "        data = json.loads(responseStr)\n",
    "        indicators = data['indicator'] \n",
    "        return indicators       \n",
    "        \n",
    "    def get_values(self,data):\n",
    "        \"\"\"\n",
    "        With this function we will manage to get the values of the dictionary and create a dataframe with\n",
    "        the info that we want.\n",
    "        \"\"\"\n",
    "        # First we get the values from the dictionary\n",
    "        data_list = list(data['values'])\n",
    "        # Then we create a df with the values that we are interested in:\n",
    "        value=[]\n",
    "        datetime=[]\n",
    "        datetime_utc=[]\n",
    "        tz_time=[]\n",
    "        geo_id=[]\n",
    "        geo_name=[]\n",
    "        for dic in data_list:\n",
    "            value.append(dic['value'])\n",
    "            datetime.append(dic['datetime'])\n",
    "            datetime_utc.append(dic['datetime_utc'])\n",
    "            tz_time.append(dic['tz_time'])\n",
    "            geo_id.append(dic['geo_id'])\n",
    "            geo_name.append(dic['geo_name'])\n",
    "        #We create the dictionary and change de data types.\n",
    "        df=pd.DataFrame({'value':value,'datetime':datetime,'datetime_utc':datetime_utc,'tz_time':tz_time,'geo_id':geo_id,'geo_name':geo_name},)\n",
    "        df['datetime']=pd.to_datetime(df['datetime'])\n",
    "        df['datetime_utc']=pd.to_datetime(df['datetime_utc'])\n",
    "        df['tz_time']=pd.to_datetime(df['tz_time'])\n",
    "        df=df[(df['geo_name']=='España')|(df['geo_name']=='Península')]\n",
    "        return df    \n",
    "    \n",
    "    def worldbank_info(self,indicator):\n",
    "        \"\"\"\n",
    "        With this function we will get the information necessary from the worldbank api. We just need to add the \n",
    "        indicator and we will get a dataframe with the date, the value and the unit\n",
    "        \"\"\"\n",
    "            # Set URL value\n",
    "        url_worldbank=' http://api.worldbank.org/v2/country/all/indicator/'+indicator+'?per_page=20000&format=json'\n",
    "            # Get the request\n",
    "        request = urllib.request.Request(url_worldbank)\n",
    "        response = urllib.request.urlopen(request)\n",
    "        responseStr = str(response.read().decode('utf-8'))\n",
    "            # Fetch json from the response\n",
    "        data = json.loads(responseStr)\n",
    "            # Then we get the values from the json\n",
    "        valor=[]\n",
    "        fecha=[]\n",
    "        unidad=[]\n",
    "        for cell in data[1]:\n",
    "            if cell['country']['value']=='Spain':\n",
    "                valor.append(cell['value'])\n",
    "                fecha.append(cell['date'])\n",
    "            else:\n",
    "                continue\n",
    "            # Create the dataframe with the values.\n",
    "        df = pd.DataFrame({'date':fecha,'value':valor})\n",
    "        df[['value']]=df[['value']].astype(float)\n",
    "        df[['date']]=df[['date']].astype(int)\n",
    "        df2 = df[(df['date']>=2014) & (df['date']<=2020)]\n",
    "        return df2\n",
    "    \n",
    "    def finance_data(self,indicator):\n",
    "        \"\"\"\n",
    "        With this function we will get the stock market historical values from Yahoo! Finance for the indicator we decide.\n",
    "        \"\"\"\n",
    "        ree = pdr.data.DataReader(indicator,'yahoo', start=datetime(2014, 4, 1), end=datetime.now())\n",
    "        return ree\n",
    "\n",
    "    def national_holidays(self):\n",
    "        \"\"\"\n",
    "        We will indicate the days that are festive for the whole country:\n",
    "            - 1 de Enero -> Año nuevo\n",
    "            - 6 de Enero -> Reyes - Epifanía del Señor\n",
    "            - 10 de Abril -> Viernes Santo\n",
    "            - 1 de Mayo -> Fiesta del Trabajo\n",
    "            - 15 de Agosto -> Asunción de la Virgen\n",
    "            - 12 de Octubre -> Día de la Hispanidad\n",
    "            - 8 de Diciembre -> Inmaculada Concepción\n",
    "            - 25 de Diciembre -> Navidad\n",
    "        \"\"\"\n",
    "        festivos=[[1,1,1],[6,1,1],[10,4,1],[1,5,1],[15,8,1],[12,10,1],[8,12,1],[25,12,1]]\n",
    "        df_fest=pd.DataFrame(festivos,columns=['day','month','value'])\n",
    "        return df_fest\n",
    "\n",
    "    def pib_data(self):\n",
    "        pib=pd.DataFrame()\n",
    "        for i in reversed(range(2014,(datetime.today().year+1))):\n",
    "            url='https://datosmacro.expansion.com/pib/espana?anio='+str(i)\n",
    "            df=pd.read_html(url)\n",
    "            pib_anio=df[0]\n",
    "            pib_anio.drop(pib_anio.tail(1).index,inplace=True)\n",
    "            pib=pib.append(pib_anio)\n",
    "        return pib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rec=data_recollection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicadores que tenemos:\n",
    "\n",
    "- 1014 : PVPC en dos tiempos\n",
    "\n",
    "- 1013 : PVPC en un tiempo\n",
    "\n",
    "- 1293 : Demanda real\n",
    "\n",
    "- 10229 : PVPC en un tiempo (si te metes en la pagina web aparece desglosado)\n",
    "\n",
    "- 10230 : PVPC en dos tiempos (si te metes en la pagina web aparece desglosado)\n",
    "\n",
    "- 600 : precio marginal mercado diario\n",
    "\n",
    "- 10027 : prevision de demanda electrica\n",
    "\n",
    "- 10010 : generacion programada de energía eólica\n",
    "\n",
    "- 10008 : Su desglose muestra la energía programada por tipo de producción del Carbón.\n",
    "\n",
    "- 612 : Precio marginal mercado intradiario sesion 1\n",
    "\n",
    "- 613 : Precio marginal mercado intradiario sesion 2\n",
    "\n",
    "- 542 : Generación prevista Solar\n",
    "\n",
    "- 460 : Calendario de la demanda diaria eléctrica peninsular según la prevision\n",
    "\n",
    "- 369 : Demana programada correción eolica\n",
    "\n",
    "- 370 : Demana programada correción solar\n",
    "\n",
    "- 541 : Previsión de la producción eólica nacional peninsular\n",
    "\n",
    "- 805 : Precio medio horario componente mercado diario\n",
    "\n",
    "- 92 : Generación Biogas\n",
    "\n",
    "- 91 : Generacion Biomasa\n",
    "\n",
    "- 79 : Generacion ciclo combinado\n",
    "\n",
    "- 95 : Generacion consumo bombeo\n",
    "\n",
    "- 88 : Generacion derivados de petroleo o carbon\n",
    "\n",
    "- 90 : Generacion energia residual\n",
    "\n",
    "- 96 : Generacion enlace baleares\n",
    "\n",
    "- 82 : Generacion eolica terrestre\n",
    "\n",
    "- 81 : Generacion gas natural\n",
    "\n",
    "- 87 : Generacion gas natural cogeneracion\n",
    "\n",
    "- 71 : Generacion hidraulica UGH\n",
    "\n",
    "- 72 : Generacion hidraulica no UGH\n",
    "\n",
    "- 77 : Generacion hulla-antracita\n",
    "\n",
    "- 78 : Generacion hulla sub-bituminosa\n",
    "\n",
    "- 74 : Generacion nuclear\n",
    "\n",
    "- 86 : Generacion oceano y geotermica\n",
    "\n",
    "- 93 : Generacion residuos domesticos\n",
    "\n",
    "- 94 : Generacion varios\n",
    "\n",
    "- 84 : Generacion solar fotovoltaica\n",
    "\n",
    "- 85 : Generacion solar termica\n",
    "\n",
    "- 89 : Generacion subproductos mineria\n",
    "\n",
    "- 73 : Generacion turbinación bombeo\n",
    "\n",
    "\n",
    "indicador yahoo:\n",
    "\n",
    " - REE.MC -> Red electrica española\n",
    " \n",
    " - %5EIBEX -> IBEX35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data: https://databank.worldbank.org/home.aspx\n",
    "\n",
    "Consumer price index (2010 = 100) (FP.CPI.TOTL)\n",
    "\n",
    "Time required to get electricity (days) (IC.ELC.TIME)\n",
    "\n",
    "Inflation, consumer prices (annual %) (FP.CPI.TOTL.ZG)\n",
    "\n",
    "Employment in industry (% of total employment) (modeled ILO estimate) (SL.IND.EMPL.ZS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the class is defined, we are ready to get all the information and manage to manipulate all the tables in order to get our final dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Yahoo! Finance info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to show, somehow, the effect of a crisis, we may add the stock market value of IBEX35 to show the evolution of the country. Moreover, we will add the stock market value for the REE as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_market_indicators=['REE.MC','%5EIBEX']\n",
    "stock_market_dict={'REE.MC':'Red_Electrica',\n",
    "                   '%5EIBEX':'IBEX35'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stock_market_list = [data_rec.finance_data(st) for st in stock_market_indicators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ESIOS info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a list in which every element will be a dataframe, so we will end up with a list of dataframes that we will join later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_list=[10027,600,612,613,369,370,92,91,79,95,88,90,96,82,81,87,71,72,77,78,74,86,93,94,84,85,89,73]\n",
    "objective=1014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the values for the indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1ff6332d5ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indicator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindicators_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-1ff6332d5ebb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indicator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindicators_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-4bf1450db0f3>\u001b[0m in \u001b[0;36mget_indicator\u001b[0;34m(self, indicator, date_today)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Authorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Token token=\\\"\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mresponseStr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Fetch json from the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1360\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_list = [data_rec.get_indicator(ind) for ind in indicators_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframes_list = [data_rec.get_values(dt) for dt in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_objective=data_rec.get_indicator(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_objective=data_rec.get_values(values_objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get the names of the indicators so we can identify them in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions=data_rec.get_list_indicators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names={}\n",
    "for i in descriptions:\n",
    "    if i['id'] in (indicators_list) :\n",
    "        names[i['id']]=i['name'].replace(' ','_')\\\n",
    "        .replace('á','a')\\\n",
    "        .replace('é','e')\\\n",
    "        .replace('í','i')\\\n",
    "        .replace('ó','o')\\\n",
    "        .replace('ú','u')\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# We do the same for the objective name:\n",
    "objective_name={}\n",
    "for i in descriptions:\n",
    "    if i['id']==1014 :\n",
    "        objective_name[i['id']]=i['name'].replace(' ','_')\\\n",
    "        .replace('á','a')\\\n",
    "        .replace('é','e')\\\n",
    "        .replace('í','i')\\\n",
    "        .replace('ó','o')\\\n",
    "        .replace('ú','u')\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the index of each name in our list of dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_indicators=[]\n",
    "for i in names.keys():\n",
    "    if i!=1014:\n",
    "        index_indicators.append(indicators_list.index(i))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_names=list(names.values())\n",
    "for i,ind in enumerate(index_indicators):\n",
    "    dataframes_list[ind].rename(columns={'value':list_of_names[i]},inplace=True)\n",
    "\n",
    "df_objective.rename(columns={'value':objective_name[1014]},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can merge all the dataframes now that we can identify the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = int(len(dataframes_list)+1)\n",
    "\n",
    "df_esios=df_objective.copy()\n",
    "for i in dataframes_list[:limit]:\n",
    "    df_esios=df_esios.merge(i.iloc[:,0:4],how='left',on=['datetime_utc','datetime','tz_time']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may create some other columns that may be useful for mergin other dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_esios['day']=df_esios['datetime_utc'].dt.day\n",
    "df_esios['month']=df_esios['datetime_utc'].dt.month\n",
    "df_esios['year']=df_esios['datetime_utc'].dt.year\n",
    "df_esios['hour']=df_esios['datetime_utc'].dt.hour\n",
    "df_esios['quarter']=df_esios['datetime_utc'].dt.quarter\n",
    "df_esios['datetime']=pd.to_datetime(df_esios['datetime'],utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. WorldBank info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info of the WorldBank API has been requested related to the industry and electricity sector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldbank_indicators=['FP.CPI.TOTL','IC.ELC.TIME','FP.CPI.TOTL.ZG','SL.IND.EMPL.ZS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldbank_list = [data_rec.worldbank_info(wb) for wb in worldbank_indicators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a dictionary with the name of each indicator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_worldbank={'FP.CPI.TOTL':'Consumer_price_index',\n",
    "               'IC.ELC.TIME':'Time_required_to_get_electricity_(days)',\n",
    "               'FP.CPI.TOTL.ZG':'Inflation,consumer_prices_(annual_%)',\n",
    "               'SL.IND.EMPL.ZS':'Employment_in_industry_(%_of_total_employment)'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we get the dataframes, we merge them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = int(len(worldbank_list)+1)\n",
    "\n",
    "df_esios2=df_esios.copy()\n",
    "for i,datafr in enumerate(worldbank_list[:limit]):\n",
    "    df_esios2=df_esios2.merge(datafr.iloc[:,0:4],how='left',left_on='year',right_on='date').drop_duplicates().drop('date',axis=1)\n",
    "    df_esios2.rename(columns={'value':dict_worldbank[worldbank_indicators[i]]},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. National holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know the national holidays in Spain so we are creating a table with this days to include this info in our final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = data_rec.national_holidays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esios3=df_esios2.merge(holidays,how='left',on=['day','month'])\\\n",
    "                    .rename(columns={'value':'holidays'})\n",
    "\n",
    "df_esios3['holidays'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are adding the Gross Domestic Product in Spain, so we can include some more economic-social data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = data_rec.pib_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns to merge\n",
    "gdp['quarter'],gdp['str'],gdp['year']=zip(*gdp['Fecha'].str.split())\n",
    "# Replace the values \n",
    "gdp['quarter'].replace({'I':'1','II':'2','III':'3','IV':'4'},inplace=True)\n",
    "# Change the datatype to integer\n",
    "gdp[['quarter','year']]=gdp[['quarter','year']].astype('int')\n",
    "# We drop columns that we don't need\n",
    "gdp.drop('str',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esios4=df_esios3.merge(gdp,how='left',on=['quarter','year'])\\\n",
    "                    .drop(['Fecha','PIB Trimestral.1'],axis=1)\\\n",
    "                    .rename({'PIB Trimestral':'PIB_Trimestral',\n",
    "                            'Var. Trim. PIB (%)':'Var_Trim_PIB_(%)',\n",
    "                            'Var. anual PIB Trim. (%)':'Var_anual_PIB_Trim_(%)'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Merging Finance info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said before, the financial data gives problems when requesting them after the esios info, so in order to get everything correct, we are now merging the info that we collected before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = int(len(stock_market_list)+1)\n",
    "\n",
    "df_final=df_esios4.copy()\n",
    "for i,datafr in enumerate(stock_market_list[:limit]):\n",
    "    datafr.index=pd.to_datetime(datafr.index, utc = True)\n",
    "    df_final=df_final.merge(datafr.iloc[:,5].to_frame(),how='left',right_index=True,left_on='datetime').drop_duplicates()\n",
    "    df_final.rename(columns={'Adj Close':stock_market_dict[stock_market_indicators[i]]},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "aemet_api='eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJqb2VsLmRlbGFjcnV6ZnVlcnRlc0Bob3RtYWlsLmNvbSIsImp0aSI6IjllYTk2Mzc3LWIxNWItNDAyYS04MmMzLTNjMzVjMzA2ODQ4NCIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNTg4NDMzOTQ5LCJ1c2VySWQiOiI5ZWE5NjM3Ny1iMTViLTQwMmEtODJjMy0zYzM1YzMwNjg0ODQiLCJyb2xlIjoiIn0.rTkcngrv3uJf4RRcJbM14af19pfE5eTT6edG1i-JyFY'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "url = \"https://opendata.aemet.es/opendata/api/valores/climatologicos/inventarioestaciones/todasestaciones/\"\n",
    "\n",
    "querystring = {\"api_key\":aemet_api}\n",
    "\n",
    "headers = {\n",
    "    'cache-control': \"no-cache\"\n",
    "    }\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "print(response.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exporting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../Exploring_data/TFM_dataframe.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
